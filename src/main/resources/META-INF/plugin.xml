<!-- Plugin Configuration File. Read more: https://plugins.jetbrains.com/docs/intellij/plugin-configuration-file.html -->
<idea-plugin>

    <!-- Unique identifier of the plugin. It should be FQN. It cannot be changed between the plugin versions. -->
    <id>com.devoxx.genie</id>

    <!-- Public plugin name should be written in Title Case.
         Guidelines: https://plugins.jetbrains.com/docs/marketplace/plugin-overview-page.html#plugin-name -->
    <name>DevoxxGenie</name>

    <!-- A displayed Vendor name or Organization ID displayed on the Plugins Page. -->
    <vendor email="info@devoxx.com" url="https://devoxx.com">Devoxx</vendor>

    <idea-version since-build="233"/>

    <!-- Description of the plugin displayed on the Plugin Page and IDE Plugin Manager.
         Simple HTML elements (text formatting, paragraphs, and lists) can be added inside of <![CDATA[ ]]> tag.
         Guidelines: https://plugins.jetbrains.com/docs/marketplace/plugin-overview-page.html#plugin-description -->
    <description><![CDATA[
        <p>Devoxx Genie IDEA Plugin</p>

        <h3>Key Features</h3>
        <UL>
            <LI>Support for local and cloud based language models: Ollama, OpenAI, Anthropic, Groq, ...</LI>
            <LI>User defined prompts for selected code snippets</LI>
        </UL>
        <h3>Set-Up</h3>
        <UL>
            <LI>Install the plugin</LI>
            <LI>Make sure you have Ollama, LMStudio or GPT4All running</LI>
            <LI>Optional: Add API Keys for Cloud based LLM providers</LI>
            <LI>Optional: Update the command prompts in the Settings</LI>
            <LI>Start using the plugin</LI>
        </UL>
    ]]></description>

    <change-notes><![CDATA[
        <h2>v0.2.10</h2>
        <UL>
            <LI>Fix #184 - Input panel has bigger min/preferred height size</LI>
            <LI>Feat #186 - Support for local LLaMA.c++ http server</LI>
            <LI>Feat #191 - Add Google model : gemini-1.5-pro-exp-0801</LI>
            <LI>Fix #181 - Last selected LLM provider is not persisted anymore</LI>
            <LI>Feat #181 - Support for multiple projects with different LLM providers & language models</LI>
            <LI>Fix #190 - Scroll output panel to the bottom when new output is added</LI>
        </UL>
        <h2>v0.2.9</h2>
        <UL>
            <LI>Fix #183 - Allow usage of remote Ollama instances</LI>
        </UL>
        <h2>v0.2.8</h2>
        <UL>
            <LI>Support Exo Local LLM cluster: more info @ https://github.com/exo-explore/exo</LI>
        </UL>
        <h2>v0.2.7</h2>
        <UL>
            <LI>Feat #177: Show Ollama models window context size</LI>
            <LI>Show 'Calc Tokens' & 'Add full project' for local models</LI>
        </UL>
        <h2>v0.2.6</h2>
        <UL>
            <LI>Renamed Gemini LLM provider to Google</LI>
            <LI>Increased Gemini Pro 1.5 window context to 2M</LI>
            <LI>Sorting LLM providers and model names alphabetically in combobox</LI>
            <LI>LLM cost calculation refactored</LI>
        </UL>
        <h2>v0.2.5</h2>
        <UL>
            <LI>Feat #171: Support OpenAI GPT 4o mini</LI>
            <LI>Fix #170: Fixed LMStudio</LI>
        </UL>
        <h2>v0.2.4</h2>
        <UL>
            <LI>Feat #164: Include all attached files in response output reference</LI>
            <LI>Feat #166: Improve code inclusion for chat context</LI>
        </UL>
        <h2>v0.2.3</h2>
        <UL>
            <LI>Feat #148: Create custom commands</LI>
            <LI>Feat #157: Calc tokens for directory</LI>
            <LI>Fix #153: Use the "Copy Project" settings when using "Add Directory to Context Window"</LI>
            <LI>Feat #159: Introduce variable TokenCalculator based on selected LLM Provider</LI>
            <LI>Feat #161: Move predefined command to custom commands</LI>
        </UL>
        <h2>v0.2.2</h2>
        <UL>
            <LI>Fix #144: Restored Gemini Pro 1.0 model</LI>
            <LI>Fix #147: CompletionException for OpenAI models</LI>
        </UL>
        <h2>v0.2.1</h2>
        <UL>
            <LI>Code refactorings</LI>
            <LI>Feat #140: Show glowing border around chat window when activate</LI>
            <LI>Fix #138 : Show editor files in file list panel</LI>
            <LI>Feat #142: Show Twitter and Preview link</LI>
        </UL>
        <h2>v0.2.0</h2>
        <UL>
            <LI>Add full project into prompt</LI>
            <LI>Calc cost of prompt</LI>
            <LI>Setup LLM input/output cost and window context in settings</LI>
            <LI>Show tokens and cost in drop down</LI>
        </UL>
        <h2>v0.1.20</h2>
        <UL>
            <LI>Updated until-version to 242</LI>
        </UL>
        <h2>v0.1.19</h2>
        <UL>
            <LI>Feat #98: Allow a streaming response to be stopped</LI>
            <LI>Feat #112: Keep selected LLM provider after settings page</LI>
            <LI>Feat #87: Auto complete commands</LI>
            <LI>Feat #33: Add files based on filtered text</LI>
            <LI>Feat #115: Show file icons in list</LI>
            <LI>Feat: Show plugin version number in settings page with GitHub link</LI>
            <LI>Fix: Support for higher timeout values</LI>
        </UL>
        <h2>v0.1.18</h2>
        <UL>
            <LI>Claude 3.5 Sonnet support (Anthropic)</LI>
            <LI>Fix #99: Improved timeout msg</LI>
            <LI>Fix #99: Show timout msg without clicking on the chat window</LI>
            <LI>Fix #99: Chat memory is correctly cleaned up when you remove a chat msg</LI>
        </UL>
        <h2>v0.1.17</h2>
        <UL>
            <LI>Feat: Split settings into different panels underneath Tools menu</LI>
            <LI>Fix #102: /help also runs the actual prompt</LI>
        </UL>
        <h2>v0.1.16</h2>
        <UL>
            <LI>Feat #90: Include System Prompt in Settings page</LI>
            <LI>Feat #88: Use TextArea for Setting prompts</LI>
        </UL>
        <h2>v0.1.15</h2>
        <UL>
            <LI>Fix #82: Wrap text to new line for streaming output.</LI>
            <LI>Feat #85: Support Web Search</LI>
        </UL>
        <h2>v0.1.14</h2>
        <UL>
            <LI>Feat #78: Set chat memory size in Settings page.</LI>
        </UL>
        <h2>v0.1.13</h2>
        <UL>
            <LI>Feat #71: Auto Abstract Syntax Tree (AST) context</span>: Automatically includes information about the superclass and class fields in the context for better code analysis and understanding.</LI>
        </UL>
        <h2>v0.1.12<h2>
        <UL>
            <LI>Feat #70: Support for streaming responses</LI>
        </UL>
        <h2>v0.1.11<h2>
        <UL>
            <LI>Feat #74: Support for Jan</LI>
        </UL>
        <h2>v0.1.10<h2>
        <UL>
            <LI>Fix #72: Code block has correct background color in Light theme</LI>
        </UL>
        <h2>v0.1.9</h2>
        <UL>
            <LI>Support light mode</LI>
        </UL>
        <h2>v0.1.8</h2>
        <UL>
            <LI>Feat #63: Support for Gemini Pro 1.5 & Flash using API Keys</LI>
            <LI>Fix for incorrect LLM selection</LI>
            <LI>Fix for chat response styling issue<LI>
            <LI>Fix prompt context issue</LI>
        </UL>
        <h2>v0.1.7</h2>
        <UL>
            <LI>Fix #61: Use correctly the chosen LLM provider and model name</LI>
        </UL>
        <h2>V0.1.6</h2>
        <UL>
            <LI>Feat #47: Support for GPT-4o</LI>
            <LI>Feat #34: User can cancel prompt execution</LI>
            <LI>Feat #19: Sort LLM providers</LI>
            <LI>Feat #38: Remember last chosen LLM provider and model</LI>
            <LI>Feat #51: Refactored DevoxxGenieToolWindowContent</LI>
            <LI>Fix #55: Files scroll panel</LI>
            <LI>Fix #57: Hide model combobox for LMStudio & GPT4All at very first startup</LI>
            <LI>Feat #59: Add complete file to context window when no code is selected</LI>
        </UL>
        <h2>V0.1.5</h2>
        <UL>
            <LI>Feat #43: Copy code to clipboard (with new lines)</LI>
        </UL>
        <h2>V0.1.4</h2>
        <UL>
            <LI>Feat #41: Support for GoLand</LI>
        </UL>
        <h2>V0.1.3</h2>
        <UL>
            <LI>Feat: Allow user to remove chat messages</LI>
            <LI>Feat: Plugin uses MessageWindowChatMemory instead of CircularQueue</LI>
        </UL>
        <h2>V0.1.2</h2>
        <UL>
            <LI>Fix: Double click adds files twice</LI>
        </UL>
        <h2>V0.1.1</h2>
        <UL>
            <LI>You can now add code snippets (via right-click popup menu) to the chat window context</LI>
        </UL>
        <h2>V0.1.0</h2>
        <UL>
            <LI>Introduction of chat conversations</LI>
            <LI>Attach files to chat context</LI>
            <LI>Output formatting with language highlighting</LI>
        </UL>
         <h2>V0.0.14</h2>
        <UL>
            <LI>Bug fix : Keep first system prompt in CircularQueue</LI>
        <h2>V0.0.14</h2>
        <UL>
            <LI>Bug fix : CircularQueue fix for first SystemMessage</LI>
        </UL>
        <h2>V0.0.13</h2>
        <UL>
            <LI>Bug fix : chat memory context</LI>
        </UL>
        <h2>V0.0.12</h2>
        <UL>
            <LI>Added chat memory (default 10 messages)</LI>
            <LI>You can turn of the chat memory in the settings</LI>
        </UL>
        <h2>V0.0.11</h2>
        <UL>
            <LI>Added Settings page link</LI>
            <LI>Catch LLM communication error</LI>
        </UL>
        <h2>V0.0.10</h2>
        <UL>
            <LI>Added more Groq and DeepInfra models</LI>
        </UL>
        <h2>V0.0.9</h2>
        <UL>
            <LI>Include button links to API Key websites & LLM providers</LI>
            <LI>Show prev/next button to scroll through chat messages</LI>
        </UL>
        <h2>V0.0.8</h2>
        <UL>
            <LI>Hide model selection for LMStudio and GPT4All</LI>
            <LI>Show correct model dropdown for the default visible LLM provider</LI>
        </UL>
        <h2>V0.0.7</h2>
        <UL>
            <LI>Support non-local LLM Providers</LI>
        </UL>
        <h2>V0.0.5</h2>
        <UL>
            <LI>Added support for a custom prompt using /custom command</LI>
        </UL>
        <h2>V0.0.4</h2>
        <UL>
            <LI>Command prompts are now externalised in Settings</LI>
        </UL>
        <h2>V0.0.3</h2>
        <UL>
            <LI>Fixed plugin compatability issues</LI>
        </UL>
        <h2>V0.0.2</h2>
        <UL>
            <LI>I18N labels and support for the French language</LI>
            <LI>Introduced CommandHandler for the predefined commands</LI>
            <LI>Settings now uses persistent store</LI>
        </UL>
        <UL>
            <LI>Initial release</LI>
        </UL>
    ]]></change-notes>

    <!-- Product and plugin compatibility requirements.
         Read more: https://plugins.jetbrains.com/docs/intellij/plugin-compatibility.html -->
    <depends>com.intellij.modules.platform</depends>
    <depends>com.intellij.modules.java</depends>

    <!-- Extension points defined by the plugin.
         Read more: https://plugins.jetbrains.com/docs/intellij/plugin-extension-points.html -->
    <extensions defaultExtensionNs="com.intellij">

        <projectConfigurable parentId="tools"
                             id="com.devoxx.genie.DevoxxGenie"
                             displayName="DevoxxGenie"
                             instance="com.devoxx.genie.ui.settings.llm.LLMProvidersConfigurable"/>

        <projectConfigurable id="com.devoxx.genie.LLMSettings"
                             parentId="com.devoxx.genie.DevoxxGenie"
                             instance="com.devoxx.genie.ui.settings.llmconfig.LLMConfigSettingsConfigurable"
                             displayName="LLM Settings"/>

        <projectConfigurable id="com.devoxx.genie.PromptSettings"
                             parentId="com.devoxx.genie.DevoxxGenie"
                             instance="com.devoxx.genie.ui.settings.prompt.PromptSettingsConfigurable"
                             displayName="Prompts"/>

        <projectConfigurable id="com.devoxx.genie.CopyProjectSettings"
                             parentId="com.devoxx.genie.DevoxxGenie"
                             instance="com.devoxx.genie.ui.settings.copyproject.CopyProjectSettingsConfigurable"
                             displayName="Copy Project"/>

        <projectConfigurable id="com.devoxx.genie.llmfeatures"
                             parentId="com.devoxx.genie.DevoxxGenie"
                             instance="com.devoxx.genie.ui.settings.costsettings.LanguageModelCostSettingsConfigurable"
                             displayName="Token Cost &amp; Context Window"/>

        <toolWindow id="DevoxxGenie"
                    anchor="right"
                    icon="/icons/pluginIcon.svg"
                    factoryClass="com.devoxx.genie.ui.DevoxxGenieToolWindowFactory"/>

        <applicationService serviceImplementation="com.devoxx.genie.ui.settings.DevoxxGenieStateService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.PromptExecutionService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.IntellijChatMemoryService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.IntellijMessageCreationService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.OllamaService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.PSIAnalyzerService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.WebSearchService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.PropertiesService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.ProjectScannerService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.ProjectContentService"/>
        <applicationService serviceImplementation="com.devoxx.genie.service.IntelliJNotificationService"/>
    </extensions>

    <extensions defaultExtensionNs="com.intellij">
        <notificationGroup id="com.devoxx.genie.notifications" displayType="BALLOON" />
        <postStartupActivity implementation="com.devoxx.genie.service.PostStartupActivity"/>
    </extensions>

    <actions>

        <action id="DevoxxGenie.AddSnippetAction"
                class="com.devoxx.genie.action.AddSnippetAction"
                text="Add To Context Window"
                icon="/icons/pluginIcon.svg"
                description="Add code snippet to context window">
            <add-to-group group-id="EditorPopupMenu" anchor="last" />
        </action>

        <action id="DevoxxGenie.AddFileAction"
                class="com.devoxx.genie.action.AddFileAction"
                text="Add File To Context Window"
                icon="/icons/pluginIcon.svg"
                description="Add file to Context">
            <add-to-group group-id="ProjectViewPopupMenu" anchor="last" />
        </action>

        <action id="AddDirectoryToContextWindow"
                class="com.devoxx.genie.action.AddDirectoryAction"
                text="Add Directory to Context Window"
                icon="/icons/pluginIcon.svg"
                description="Add the selected directory to the context window">
            <add-to-group group-id="ProjectViewPopupMenu"/>
        </action>

        <action id="CopyDirectoryToClipboard"
                class="com.devoxx.genie.action.AddDirectoryAction"
                text="Copy Directory to Clipboard"
                icon="/icons/pluginIcon.svg"
                description="Copy the selected directory content to clipboard">
            <add-to-group group-id="ProjectViewPopupMenu" anchor="after" relative-to-action="AddDirectoryToContextWindow"/>
        </action>

        <action id="CalcTokenDirectory"
                class="com.devoxx.genie.action.CalcTokensForDirectoryAction"
                text="Calc Tokens for Directory"
                icon="/icons/pluginIcon.svg"
                description="Calculate the tokens for selected directory">
            <add-to-group group-id="ProjectViewPopupMenu" anchor="after" relative-to-action="CopyDirectoryToClipboard"/>
        </action>
    </actions>
</idea-plugin>
